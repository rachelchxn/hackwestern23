{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install + import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (4.8.1.78)\n",
      "Requirement already satisfied: face_recognition in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: openai in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (0.28.0)\n",
      "Requirement already satisfied: SpeechRecognition in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: firebase_admin in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (6.2.0)\n",
      "Requirement already satisfied: pyserial in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (3.5)\n",
      "Requirement already satisfied: google-cloud-speech in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 7)) (2.22.0)\n",
      "Requirement already satisfied: requests in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: sounddevice in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: pyaudio in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 10)) (0.2.14)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from opencv-python->-r requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: Click>=6.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (19.24.2)\n",
      "Requirement already satisfied: Pillow in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (10.1.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from openai->-r requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from openai->-r requirements.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.13.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.22.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (0.13.1)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.5.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.9.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.13.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.108.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-speech->-r requirements.txt (line 7)) (4.25.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-speech->-r requirements.txt (line 7)) (1.22.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (3.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (2.1.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from sounddevice->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from cachecontrol>=0.12.6->firebase_admin->-r requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: pycparser in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from CFFI>=1.0->sounddevice->-r requirements.txt (line 9)) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.61.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.59.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.59.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-firestore>=2.9.1->firebase_admin->-r requirements.txt (line 5)) (2.3.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 5)) (2.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin->-r requirements.txt (line 5)) (41.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (23.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelchen/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import pyaudio\n",
    "import uuid\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "\n",
    "cred = firebase_admin.credentials.Certificate('hw23-e0512-firebase-adminsdk-3ax9k-293086f6f4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading image...\n",
      "https://storage.googleapis.com/hw23-e0512.appspot.com/test\n"
     ]
    }
   ],
   "source": [
    "from firebase_admin import credentials, firestore, storage\n",
    "from google.cloud import storage\n",
    "\n",
    "from functions.firebase import uploadImageFromBlob, uploadImageFromPath\n",
    "\n",
    "# firebase_app = firebase_admin.initialize_app(cred,{\n",
    "#     'storageBucket': 'gs://hw23-e0512.appspot.com'\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_encodings_from_firestore():\n",
    "    fetched_encodings = []\n",
    "    fetched_names = []\n",
    "    \n",
    "    # Fetch data from Firestore\n",
    "    docs = db.collection('people').stream()\n",
    "    for doc in docs:\n",
    "        data = doc.to_dict()\n",
    "        if 'image_enc' in data and 'name' in data:\n",
    "            fetched_encodings.append(np.array(data['image_enc']))\n",
    "            fetched_names.append(data['name'])\n",
    "    \n",
    "    return fetched_encodings, fetched_names\n",
    "\n",
    "def find_similar_face_key(face_encoding, faces_dict, tolerance=0.6):\n",
    "    for face_key in faces_dict.keys():\n",
    "        if np.linalg.norm(np.array(face_key) - face_encoding) < tolerance:\n",
    "            return face_key\n",
    "    return None\n",
    "\n",
    "# def uploadImageFromBlob(imageblob, image_name):\n",
    "#     print(\"uploading image...\")\n",
    "    \n",
    "#     # bucket = storage.bucket(\"hw23-e0512.appspot.com\")\n",
    "#     bucket = storage.bucket()\n",
    "#     blob = bucket.blob(image_name)\n",
    "#     image = imageblob[0].transpose(1, 2, 0)  # Convert from (channels, height, width) to (height, width, channels)\n",
    "#     image = np.uint8(image)  # Convert to unsigned byte format\n",
    "\n",
    "#     # Convert to PIL Image\n",
    "#     pil_image = Image.fromarray(image)\n",
    "\n",
    "#     # Convert to Byte Stream for uploading\n",
    "#     byte_stream = io.BytesIO()\n",
    "#     pil_image.save(byte_stream, format='JPEG')\n",
    "#     byte_stream.seek(0)\n",
    "\n",
    "#     blob.upload_from_file(byte_stream, content_type='image/jpeg')\n",
    "\n",
    "#     return blob.public_url\n",
    "\n",
    "\n",
    "# Dictionary to track unrecognized faces\n",
    "unrecognized_faces = {}\n",
    "unrecognized_threshold = 3  # Number of frames to confirm an unrecognized face\n",
    "\n",
    "video_capture = cv2.VideoCapture(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelchen/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X13sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X13sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X13sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m video_capture \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.cloud.firestore import SERVER_TIMESTAMP\n",
    "\n",
    "def camera_operations(video_capture):\n",
    "    face_encodings_from_db, face_names_from_db = fetch_encodings_from_firestore()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        # print(frame)\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = np.ascontiguousarray(small_frame[:, :, ::-1])\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            top = max(top, 0)\n",
    "            right = min(right, frame.shape[1])\n",
    "            bottom = min(bottom, frame.shape[0])\n",
    "            left = max(left, 0)\n",
    "\n",
    "            face_image = frame[top:bottom, left:right]\n",
    "            \n",
    "            if face_image.size > 0:\n",
    "                matches = face_recognition.compare_faces(face_encodings_from_db, face_encoding, tolerance=0.5)\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = face_names_from_db[first_match_index]\n",
    "                else:\n",
    "                    # Generate unique ID for the image and upload it\n",
    "                    unique_id = str(uuid.uuid4())\n",
    "                    image_path = f\"faces/{unique_id}.jpg\"\n",
    "                    # save the frame into the images folder\n",
    "                    cv2.imwrite(image_path, face_image)\n",
    "                    image_url = uploadImageFromPath(image_path, image_path)\n",
    "                    print(image_url)\n",
    "\n",
    "                    # Save the encoding and image URL in Firestore\n",
    "                    doc_ref = db.collection('people').document(unique_id)\n",
    "                    doc_ref.set({\n",
    "                        'image_enc': face_encoding.tolist(),\n",
    "                        'name': \"Unnamed Person\",\n",
    "                        'image_url': image_url,\n",
    "                        'timestamp': SERVER_TIMESTAMP \n",
    "                    })\n",
    "\n",
    "                    # Update local encodings for real-time comparison\n",
    "                    face_encodings_from_db.append(face_encoding)\n",
    "                    face_names_from_db.append(\"Unnamed Person\")\n",
    "\n",
    "                    name = \"Unnamed Person\"\n",
    "\n",
    "                face_names.append(name)\n",
    "\n",
    "            # Drawing the results on the frame\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            cv2.imshow('Video', frame)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading image...\n",
      "https://storage.googleapis.com/hw23-e0512.appspot.com/faces/ae55167e-e619-426b-923f-a74580072ca2.jpg\n",
      "uploading image...\n",
      "https://storage.googleapis.com/hw23-e0512.appspot.com/faces/db72e165-0c86-4007-9be0-c7b75779d492.jpg\n"
     ]
    }
   ],
   "source": [
    "camera_operations(cv2.VideoCapture(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install + import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_transcription():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Say something!\")\n",
    "        while True:\n",
    "            audio = recognizer.listen(source)\n",
    "            try:\n",
    "                # Transcribe the audio to text\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(\"Transcription: \" + text)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_transcription():\n",
    "    recognizer = sr.Recognizer()\n",
    "    output = \"\"\n",
    "    with sr.Microphone() as source:\n",
    "        # Adjust for ambient noise once at the beginning\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        print(\"Say something!\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "\n",
    "                # Transcribe the audio to text\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(text)\n",
    "                output += text\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Error; {0}\".format(e))\n",
    "            except sr.WaitTimeoutError:\n",
    "                print(\"No speech detected, try again...\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/q4/w5wd298x2j51mk7bkv38kmt80000gn/T/ipykernel_37531/1977272103.py\", line 66, in camera_operations\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Running camera operations in a separate thread\n",
    "camera_thread = threading.Thread(target=camera_operations)\n",
    "camera_thread.start()\n",
    "\n",
    "# Running audio transcription in the main thread\n",
    "audio_transcription()\n",
    "\n",
    "# Wait for the camera thread to finish\n",
    "camera_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "user = \"Rachel\"\n",
    "dialogue = f'''hi nice to meet you what's your name my name is Xander chin\n",
    "erase my name is Rachel\n",
    "\n",
    "participating in hack Western 10 by\n",
    "remember people's names oh what a coincidence I'm doing that'''\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": f'''Extract the name and key information about the person {user} is talking to in relation to {user} from this conversation dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "This is going to be displayed to {user} as a reminder to them about this person. Use this format and fill in the blanks, if name or location info is not available, assign it [Unknown].:\n",
    "Name: [insert name]\n",
    "Where they are: [insert location]\n",
    "Points:\n",
    "- [insert point 1]\n",
    "- [insert point 2]\n",
    "- [insert point 3]...\n",
    "'''\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Xander Chin\n",
      "Where they are: [Unknown]\n",
      "Points:\n",
      "- Participating in hack Western 10\n",
      "- Working on remembering people's names.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m api_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAIzaSyBN197RE1Jgm3F_oQ8OkRIXg9RB6xPXL3g\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m audio_file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m response \u001b[39m=\u001b[39m transcribe(api_key, audio_file_path, sample_rate)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(json\u001b[39m.\u001b[39mdumps(response, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://speech.googleapis.com/v1/speech:recognize?key=\u001b[39m\u001b[39m{\u001b[39;00mapi_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Prepare request payload with audio content\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mLINEAR16\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msampleRateHertz\u001b[39m\u001b[39m\"\u001b[39m: sample_rate,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlanguageCode\u001b[39m\u001b[39m\"\u001b[39m: language_code\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: audio_content\u001b[39m.\u001b[39;49mdecode(\u001b[39m'\u001b[39m\u001b[39mUTF-8\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Assuming audio_content is already Base64 encoded\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Send the POST request\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X31sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(url, json\u001b[39m=\u001b[39mdata)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import io\n",
    "import wave\n",
    "\n",
    "def record_audio(duration=5, sample_rate=48000):\n",
    "    \"\"\"Record audio from the microphone.\"\"\"\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()\n",
    "    return recording\n",
    "\n",
    "def convert_to_wav(audio, sample_rate):\n",
    "    \"\"\"Convert the NumPy array audio to WAV format.\"\"\"\n",
    "    byte_io = io.BytesIO()\n",
    "    with wave.open(byte_io, 'w') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(np.int16(audio).tobytes())\n",
    "    return byte_io.getvalue()\n",
    "\n",
    "def transcribe(api_key, audio_content, sample_rate, language_code=\"en-US\"):\n",
    "    url = f\"https://speech.googleapis.com/v1/speech:recognize?key={api_key}\"\n",
    "\n",
    "    # Prepare request payload with audio content\n",
    "    data = {\n",
    "        \"config\": {\n",
    "            \"encoding\": \"LINEAR16\",\n",
    "            \"sampleRateHertz\": sample_rate,\n",
    "            \"languageCode\": language_code\n",
    "        },\n",
    "        \"audio\": {\n",
    "            \"content\": audio_content.decode('UTF-8')  # Assuming audio_content is already Base64 encoded\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Error code {response.status_code}: {response.text}\")\n",
    "\n",
    "# Record audio from the microphone\n",
    "sample_rate = 48000  # Or use 16000\n",
    "recorded_audio = record_audio(duration=5, sample_rate=sample_rate)\n",
    "audio_content = convert_to_wav(recorded_audio, sample_rate)\n",
    "\n",
    "# Usage example\n",
    "api_key = \"AIzaSyBN197RE1Jgm3F_oQ8OkRIXg9RB6xPXL3g\"\n",
    "audio_file_path = \"test.wav\"\n",
    "response = transcribe(api_key, audio_file_path, sample_rate)\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there I am amazing\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "if isinstance(response, str):\n",
    "    response = json.loads(response)\n",
    "\n",
    "# Access the transcript\n",
    "transcript = response['results'][0]['alternatives'][0]['transcript']\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
