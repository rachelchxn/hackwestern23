{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install + import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (4.8.1.78)\n",
      "Requirement already satisfied: face_recognition in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: openai in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (0.28.0)\n",
      "Requirement already satisfied: SpeechRecognition in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: firebase_admin in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (6.2.0)\n",
      "Collecting pyserial\n",
      "  Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 3.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from opencv-python->-r requirements.txt (line 1)) (1.26.2)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (19.24.2)\n",
      "Requirement already satisfied: Pillow in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (10.1.0)\n",
      "Requirement already satisfied: Click>=6.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from face_recognition->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from openai->-r requirements.txt (line 3)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from openai->-r requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from openai->-r requirements.txt (line 3)) (3.9.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.108.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.9.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.13.1)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (0.13.1)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.5.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.22.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from firebase_admin->-r requirements.txt (line 5)) (2.13.0)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from cachecontrol>=0.12.6->firebase_admin->-r requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (4.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (2.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.61.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.59.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (1.59.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (4.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-firestore>=2.9.1->firebase_admin->-r requirements.txt (line 5)) (2.3.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-firestore>=2.9.1->firebase_admin->-r requirements.txt (line 5)) (1.22.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 5)) (2.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client>=1.7.8->firebase_admin->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]<3.0.0dev,>=1.22.1->firebase_admin->-r requirements.txt (line 5)) (0.5.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin->-r requirements.txt (line 5)) (41.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin->-r requirements.txt (line 5)) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rachelchen/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->-r requirements.txt (line 3)) (1.4.0)\n",
      "Installing collected packages: pyserial\n",
      "Successfully installed pyserial-3.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelchen/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import pyaudio\n",
    "import uuid\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "\n",
    "cred = firebase_admin.credentials.Certificate('hw23-e0512-firebase-adminsdk-3ax9k-293086f6f4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firebase_admin import credentials, firestore, storage\n",
    "from google.cloud import storage\n",
    "\n",
    "from functions.firebase import read_document, create_document, uploadImageFromBytes \n",
    "\n",
    "firebase_app = firebase_admin.initialize_app(cred,{\n",
    "    'storageBucket': 'gs://hw23-e0512.appspot.com'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m db \u001b[39m=\u001b[39m firestore\u001b[39m.\u001b[39mclient()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m bucket \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mbucket(\u001b[39m'\u001b[39;49m\u001b[39mgs://hw23-e0512.appspot.com\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "db = firestore.client()\n",
    "bucket = storage.bucket('gs://hw23-e0512.appspot.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rachel_image = face_recognition.load_image_file(\"rachel.jpg\")\n",
    "rachel_encoding = face_recognition.face_encodings(rachel_image)[0]\n",
    "\n",
    "xander_image = face_recognition.load_image_file(\"xander.jpg\")\n",
    "xander_encoding = face_recognition.face_encodings(xander_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = [\n",
    "    rachel_encoding,\n",
    "    xander_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Rachel Chen\",\n",
    "    \"Xander Chin\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_encodings_from_firestore():\n",
    "    fetched_encodings = []\n",
    "    fetched_names = []\n",
    "    \n",
    "    # Fetch data from Firestore\n",
    "    docs = db.collection('people').stream()\n",
    "    for doc in docs:\n",
    "        data = doc.to_dict()\n",
    "        if 'image_enc' in data and 'name' in data:\n",
    "            fetched_encodings.append(np.array(data['image_enc']))\n",
    "            fetched_names.append(data['name'])\n",
    "    \n",
    "    return fetched_encodings, fetched_names\n",
    "\n",
    "def find_similar_face_key(face_encoding, faces_dict, tolerance=0.6):\n",
    "    for face_key in faces_dict.keys():\n",
    "        if np.linalg.norm(np.array(face_key) - face_encoding) < tolerance:\n",
    "            return face_key\n",
    "    return None\n",
    "\n",
    "def upload_face_image(image, path):\n",
    "    \"\"\"Uploads the face image to Firebase Storage.\"\"\"\n",
    "    pil_image = Image.fromarray(image)\n",
    "    byte_stream = io.BytesIO()\n",
    "    pil_image.save(byte_stream, format='JPEG')\n",
    "    byte_stream.seek(0)\n",
    "\n",
    "    blob = bucket.blob(path)\n",
    "    blob.upload_from_file(byte_stream, content_type='image/jpeg')\n",
    "    return blob.public_url\n",
    "\n",
    "\n",
    "# Dictionary to track unrecognized faces\n",
    "unrecognized_faces = {}\n",
    "unrecognized_threshold = 2  # Number of frames to confirm an unrecognized face\n",
    "\n",
    "video_capture = cv2.VideoCapture(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def camera_operations(video_capture):\n",
    "    face_encodings_from_db, face_names_from_db = fetch_encodings_from_firestore()\n",
    "    unrecognized_faces = {}\n",
    "    unrecognized_threshold = 2  # Set your threshold\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = np.ascontiguousarray(small_frame[:, :, ::-1])\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            top = max(top, 0)\n",
    "            right = min(right, frame.shape[1])\n",
    "            bottom = min(bottom, frame.shape[0])\n",
    "            left = max(left, 0)\n",
    "\n",
    "            face_image = frame[top:bottom, left:right]\n",
    "            \n",
    "            if face_image.size > 0:\n",
    "                matches = face_recognition.compare_faces(face_encodings_from_db, face_encoding, tolerance=0.5)\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = face_names_from_db[first_match_index]\n",
    "                else:\n",
    "                    # Generate unique ID for the image and upload it\n",
    "                    unique_id = str(uuid.uuid4())\n",
    "                    image_path = f\"faces/{unique_id}.jpg\"\n",
    "                    # image_url = upload_face_image(face_image, image_path)\n",
    "                    image_url = uploadImageFromBytes(face_image, image_path)\n",
    "\n",
    "                    # Save the encoding and image URL in Firestore\n",
    "                    doc_ref = db.collection('people').document(unique_id)\n",
    "                    doc_ref.set({\n",
    "                        'image_enc': face_encoding.tolist(),\n",
    "                        'name': \"Unnamed Person\",\n",
    "                        # 'image_url': image_url\n",
    "                    })\n",
    "\n",
    "                    # Update local encodings for real-time comparison\n",
    "                    face_encodings_from_db.append(face_encoding)\n",
    "                    face_names_from_db.append(\"Unnamed Person\")\n",
    "\n",
    "                    name = \"Unnamed Person\"\n",
    "\n",
    "                face_names.append(name)\n",
    "\n",
    "            # Drawing the results on the frame\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            cv2.imshow('Video', frame)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "camera_operations(video_capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m camera_operations(cv2\u001b[39m.\u001b[39;49mVideoCapture(\u001b[39m1\u001b[39;49m))\n",
      "\u001b[1;32m/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m rgb_small_frame \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(small_frame[:, :, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m face_locations \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39mface_locations(rgb_small_frame)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m face_encodings \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39;49mface_encodings(rgb_small_frame, face_locations)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m face_names \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rachelchen/Documents/GitHub/hackwestern23/test.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m (top, right, bottom, left), face_encoding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(face_locations, face_encodings):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:213\u001b[0m, in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mface_encodings\u001b[39m(face_image, known_face_locations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, num_jitters\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m    Given an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m    :return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     raw_landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m [np\u001b[39m.\u001b[39marray(face_encoder\u001b[39m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[39mfor\u001b[39;00m raw_landmark_set \u001b[39min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:165\u001b[0m, in \u001b[0;36m_raw_face_landmarks\u001b[0;34m(face_image, face_locations, model)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    163\u001b[0m     pose_predictor \u001b[39m=\u001b[39m pose_predictor_5_point\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m [pose_predictor(face_image, face_location) \u001b[39mfor\u001b[39;00m face_location \u001b[39min\u001b[39;00m face_locations]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/face_recognition/api.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    163\u001b[0m     pose_predictor \u001b[39m=\u001b[39m pose_predictor_5_point\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m [pose_predictor(face_image, face_location) \u001b[39mfor\u001b[39;00m face_location \u001b[39min\u001b[39;00m face_locations]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera_operations(cv2.VideoCapture(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install + import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_transcription():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        print(\"Say something!\")\n",
    "        while True:\n",
    "            audio = recognizer.listen(source)\n",
    "            try:\n",
    "                # Transcribe the audio to text\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(\"Transcription: \" + text)\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_transcription():\n",
    "    recognizer = sr.Recognizer()\n",
    "    output = \"\"\n",
    "    with sr.Microphone() as source:\n",
    "        # Adjust for ambient noise once at the beginning\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        print(\"Say something!\")\n",
    "        while True:\n",
    "            try:\n",
    "                audio = recognizer.listen(source, phrase_time_limit=5)\n",
    "\n",
    "                # Transcribe the audio to text\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(text)\n",
    "                output += text\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Error; {0}\".format(e))\n",
    "            except sr.WaitTimeoutError:\n",
    "                print(\"No speech detected, try again...\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/q4/w5wd298x2j51mk7bkv38kmt80000gn/T/ipykernel_37531/1977272103.py\", line 66, in camera_operations\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Running camera operations in a separate thread\n",
    "camera_thread = threading.Thread(target=camera_operations)\n",
    "camera_thread.start()\n",
    "\n",
    "# Running audio transcription in the main thread\n",
    "audio_transcription()\n",
    "\n",
    "# Wait for the camera thread to finish\n",
    "camera_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "user = \"Rachel\"\n",
    "dialogue = f'''hi nice to meet you what's your name my name is Xander chin\n",
    "erase my name is Rachel\n",
    "\n",
    "participating in hack Western 10 by\n",
    "remember people's names oh what a coincidence I'm doing that'''\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": f'''Extract the name and key information about the person {user} is talking to in relation to {user} from this conversation dialogue:\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "This is going to be displayed to {user} as a reminder to them about this person. Use this format and fill in the blanks, if name or location info is not available, assign it [Unknown].:\n",
    "Name: [insert name]\n",
    "Where they are: [insert location]\n",
    "Points:\n",
    "- [insert point 1]\n",
    "- [insert point 2]\n",
    "- [insert point 3]...\n",
    "'''\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Xander Chin\n",
      "Where they are: [Unknown]\n",
      "Points:\n",
      "- Participating in hack Western 10\n",
      "- Working on remembering people's names.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
